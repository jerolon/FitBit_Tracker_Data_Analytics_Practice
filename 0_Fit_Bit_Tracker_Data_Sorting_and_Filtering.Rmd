---
title: "Fit Bit Tracker Data Sorting and Filtering"
author: "Jeronimo Miranda"
date: '2023-05-05'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(skimr)
library(dplyr)
library(lubridate)
library(stringr)
library(tidyr)
library(ggplot2)
```

```{r directory setup, include = FALSE}
rstudioapi::getActiveDocumentContext
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

## Loading and exploring the data
We are using the data from <https://www.kaggle.com/datasets/arashnic/fitbit>. 
Assume the path to the data is in a folder above where the repository is. This is an exploration of the data's quirks.

### Daily activity data

I am loading the Ids as character because summary statistics like mean or median are irrelevant whereas string comparisons like "do all Ids have the same amount of characters" and "how many are unique" are important to know for knowing about the data integrity.

```{r data loading, message=FALSE, warning=FALSE}
data_path <- "../Fitabase Data 4.12.16-5.12.16/"
dailyActivity <- read_csv(paste0(data_path,"dailyActivity_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityDate = col_date(format = "%m/%d/%Y")))
skim_without_charts(dailyActivity)
```

Loaded the dates in the correct format. Since apart from date and Id all columns are numeric, it makes sense to use skim_without_charts which gives a statistical summary of each variable. The function output is rendered as an html table, which is quite nice.

What we can see from this summary:

* 33 unique Ids, all have 10 characters.
* Data was collected for 31 days, from april 12 to may 12.
* The minimum for **all** numeric variables is 0. This suggests empty days, maybe just days that people did not wear their devices. These rows should be eliminated.
* Column names do not need to be cleaned
* The data is in long format
* This data can help answer our question by telling us how frequently people track different activities. Before any analysis we can see that most activity is done via trackerDistance rather than LoggedActivities

Total distance is not the sum of TrackerDistance and LoggedActivitiesDistance, as one could assume. For most records, TotalDistance and TrackerDistance are the same, thought there are exceptions. Rather it seems to be the sum of the ActiveDistances columns. Lack of metadata is killing me here.

```{r sum of distances}
filter(dailyActivity, TotalDistance != (LoggedActivitiesDistance + TrackerDistance))
```
#### Number of days tracked

We group the days by Id and then plot a histogram of how many days people in the dataset were tracked
```{r number of days tracked, echo=FALSE, message=FALSE, warning=FALSE}
select(dailyActivity, Id, ActivityDate) %>% group_by(Id) %>% summarise(N_days = n()) %>% ggplot() + geom_histogram(aes(x = N_days)) + theme_bw() + 
  labs(title = "Days of activity", subtitle = "Frequency of the number of days tracked per user")
```

User **4057192912** is an outlier, having data only for four days.

Running `select(dailyActivity, Id, ActivityDate) %>% distinct()` shows that there are no duplicate dates for any Id.

Data seems very redundant. The files `dailyCalories_merged.csv`, `daily_Intensities_merged` and `dailySteps_merged.csv` are just column subsets of `dailyActivity_merged.csv`

### Heartrate seconds data

```{r load heart rate, warning=FALSE}
heartrate_seconds <- read_csv(paste0(data_path,"heartrate_seconds_merged.csv"), 
    col_types = cols(Id = col_character(), Time = col_datetime(format = "%m/%d/%Y %H:%M:%S %p"), Value = col_double()))
## Splitting the date time column into date and time
heartrate_date_time <- transmute(heartrate_seconds, Id, date_time = Time, Value, hour_of_day = hms::as_hms(date_time), dia = date(date_time))
skim_without_charts(heartrate_date_time)
```

Only 14 out of 33 volunteers use a tracker that gets heart-rate data

These graphics span 24 hour periods. So you can see that only 3 people do not use the device to track sleep. The data is smoothed for every user, so day to day variability is lost. Still you can see some patterns of when people tend to exercise more consistently. Later we can average by the heart rate in sliding windows to plot different days for each user. It is just that the raw data every 5 seconds is way too dense to be visualized directly, even for a single day for a single user.

```{r graph of heart rates, echo=FALSE}
heartrate_date_time %>% ggplot() + geom_smooth(aes(x = hour_of_day, y = Value), se=FALSE) + facet_wrap(~Id) + labs(title = "Heart rate throught the day", subtitle = "Trendline of heart rate per user")
```

### Loading and checking hourly data
Finally figured out how to parse date times from readr. There are three files with hourly aggregated data. Skim without chart is done after merging all three files.
```{r hourly loading, warning=FALSE}
hourlyCalories <- read_csv(paste0(data_path, "hourlyCalories_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityHour = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

hourlyIntensities <- read_csv(paste0(data_path, "hourlyIntensities_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityHour = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

hourlySteps <- read_csv(paste0(data_path, "hourlySteps_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityHour = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))
hourlyActivity <- inner_join(hourlyCalories, hourlyIntensities, by = c("Id","ActivityHour")) %>% inner_join(hourlySteps, by = c("Id", "ActivityHour"))

skim_without_charts(hourlyActivity)
```

- All three datasets are complete, the joins by Id and hourlyActivity conserve the 22099 hours.
- What is Intensity? How is it defined and why does it not appear in dailyActivity? Maybe it is some function of hear-rate and steps.

There is data for 24 hours most days. Does this mean that people almost never take off their devices? Or just that there is hourly data regardless of whether people wear their fitbits?

```{r hoursTracked, echo=TRUE, message=FALSE, warning=FALSE}
hourlyActivity %>% mutate(fecha = date(ActivityHour)) %>% group_by(fecha, Id) %>% summarise(hoursTracked = n()) %>% ungroup() %>% group_by(hoursTracked) %>% summarise(days = n()) %>% arrange(desc(hoursTracked))
```

Take the intervals between rows. All NAs are when users Id change. All other gaps are one hour long. Hard to think that users wore their fitbits for two months continuously. Heart rate data can be used in the analysis section to answer this question.

```{r duration of tracking per user}
hourlyActivity %>% select(Id, ActivityHour) %>%
  mutate(fecha = date(ActivityHour)) %>% 
  group_by(Id) %>% 
  mutate(gap = ActivityHour - lag(ActivityHour)) %>% ungroup() %>%  group_by(gap) %>% summarise(gaps = n())
```
Last, a summary table looking at when the tracking data begins and ends for each user: the beginning is the same for all: 12 am on april 12. This suggests that the data was cut to give them a consistent start date, because users did not just start using their tracker on midnight the same day. The end times are variable, even when most data ends on the same day.
```{r hourly tracking ranges by user}
hourlyActivity %>% group_by(Id) %>% summarise(beginning_of_tracking = min(ActivityHour), end_of_tracking = max(ActivityHour))

```
### Loading minute data

Minute data has the peculiarity that each feature is present in **Wide** and **Narrow** modalities. My first guess was *Wide* meant that each user had its own column, but it is actually that files have a row per hour and each column is a minute. I do not understand the rationality behind this, but wide formats are often useful for visualizations. In any case, it is a good opportunity to use the package called "lubridate".

The features present with minute resolution are:

- Calories
- Intensities
- Steps
- METs (Only present in narrow format God knows why)
- Sleep (Not specified whether it is narrow or wide format)

#### Calories by the minute

```{r minute calories, echo=TRUE, message=FALSE, warning=FALSE}
minuteCaloriesNarrow <- read_csv(paste0(data_path, "minuteCaloriesNarrow_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityMinute = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

minuteCaloriesWide <- read_csv(paste0(data_path,"minuteCaloriesWide_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityHour = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

#This Transforms the wide data to narrow
minuteCalWide_toNarrow <- minuteCaloriesWide %>% pivot_longer(names_to = "Minute", values_to = "Calories", cols = starts_with("Calories"), names_transform = readr::parse_number)

#Note the "minutes" function when adding to ActivityHour, otherwise the numeric column would get added as seconds
minuteCalWide_toNarrow <- minuteCalWide_toNarrow %>% transmute(Id, ActivityMinute = ActivityHour + minutes(Minute), Calories) %>% arrange(Id)

```

#### Discrepancies between the files

Already the number of rows differs between both files
```{r calorie comparison, echo=TRUE, message=FALSE, warning=FALSE}
nrow(minuteCaloriesNarrow) - (60 * nrow(minuteCaloriesWide))
```
The minuteCaloriesNarrow file and the minuteCaloriesNarrow differ in data, for some random reason.

We will just make a new minuteCalories object as the intersection of both files, the Wide file previously transformed to long format in a chunk above. Delete the intermediate files to save memory

```{r minute calories merged, message=FALSE, warning=FALSE}
minuteCalories <- union(minuteCaloriesNarrow, minuteCalWide_toNarrow)
rm(minuteCaloriesNarrow)
rm(minuteCalWide_toNarrow)
```

Now we will compare these data with the previously loaded hourly data. In the code below, note the combination of the functions `hours` which transforms a number to hours and `hour` which extracts the hour info from a date time.

```{r comparison of minute and hour data, message=FALSE, warning=FALSE}
minuteCalories 

#Group the minuteCalories by hour and sum the cals. A column in the summarise function lets us check that we are not including hours where not all minutes are present
minuteCalories2hour <- minuteCalories %>% transmute(Id, ActivityHour = date(ActivityMinute) + hours(hour(ActivityMinute)), Calories) %>%
group_by(Id, ActivityHour) %>% 
summarise(Calories = round(sum(Calories)), n_minutes = n())

minuteCalories2hour <- minuteCalories2hour %>% filter(n_minutes == 60) %>% select(-n_minutes)
setdiff(minuteCalories2hour, hourlyCalories)
```

Not clear what is going on. A clue might be in the days that do not have the full 24 hours. That is, the hourly data only has 24 hour days. But the minute data includes the hours from the days where this is not the case. Even though the number of different rows are small, the discrepancy should be taken into account depending on the analysis.

#### Intensities and Steps data
We loaded Intensities and steps data, which are also in Wide/Narrow formats and did the same operations as above for the calories, therefore, we do not show that code here. Nevertheless, we  will merge the three files into a single minute dataframe called "minuteActivity" that will be used in the next section.
```{r load intensities and steps, message=FALSE, warning=FALSE, include=FALSE}
minuteIntensitiesNarrow <- read_csv(paste0(data_path,"minuteIntensitiesNarrow_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityMinute = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

minuteIntensitiesWide <- read_csv(paste0(data_path,"minuteIntensitiesWide_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityHour = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

#This Transforms the wide data to narrow
minuteIntWide_toNarrow <- minuteIntensitiesWide %>% pivot_longer(names_to = "Minute", values_to = "Intensity", cols = starts_with("Intensity"), names_transform = readr::parse_number)

#Transform the hour data to hour plus minutes in order to merge with the narrow data
minuteIntWide_toNarrow <- minuteIntWide_toNarrow %>% transmute(Id, ActivityMinute = ActivityHour + minutes(Minute), Intensity) %>% arrange(Id)

##Merging
minuteIntensity <- union(minuteIntensitiesNarrow, minuteIntWide_toNarrow)
rm(minuteIntensitiesNarrow)
rm(minuteIntWide_toNarrow)

## Steps
minuteStepsNarrow <- read_csv(paste0(data_path,"minuteStepsNarrow_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityMinute = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

minuteStepsWide <- read_csv(paste0(data_path,"minuteStepsWide_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityHour = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))


#This Transforms the wide data to narrow
minuteStepsWide_toNarrow <- minuteStepsWide %>% pivot_longer(names_to = "Minute", values_to = "Steps", cols = starts_with("Steps"), names_transform = readr::parse_number)

#Transform the hour data to hour plus minutes in order to merge with the narrow data
minuteStepsWide_toNarrow <- minuteStepsWide_toNarrow %>% transmute(Id, ActivityMinute = ActivityHour + minutes(Minute), Steps) %>% arrange(Id)

##Merging
minuteSteps <- union(minuteStepsNarrow, minuteStepsWide_toNarrow)
rm(minuteStepsNarrow)
rm(minuteStepsWide_toNarrow)

###Triple join
minuteActivity <- inner_join(minuteCalories, minuteIntensity, by = c("Id","ActivityMinute")) %>% inner_join(minuteSteps, by = c("Id", "ActivityMinute"))
```

### Loading METs data
METs, or [Metabolically equivalent minutes](https://en.wikipedia.org/wiki/Metabolic_equivalent_of_task) is, according to wikipedia: "the objective measure of the ratio of the rate at which a person expends energy, relative to the mass of that person". It also says it is a way to grade activity levels. Therefore, we will join it with the minute data set in order to compare the relationships between them. 

```{r METs loading, message=FALSE, warning=FALSE}
minuteMETsNarrow <- read_csv(paste0(data_path,"minuteMETsNarrow_merged.csv"), 
    col_types = cols(Id = col_character(), 
        ActivityMinute = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

mergeMETsActivity <- inner_join(minuteActivity, minuteMETsNarrow)
library(gridExtra)
g1 <- mergeMETsActivity %>% ggplot(aes(x = Intensity, y = METs)) + geom_point() + theme_bw()
g2 <- mergeMETsActivity %>% ggplot(aes(x = Steps, y = METs)) + geom_point() + theme_bw()
g3 <- mergeMETsActivity %>% ggplot(aes(x = Calories, y = METs)) + geom_point() + theme_bw()
g4 <- mergeMETsActivity %>% ggplot(aes(x = Steps, y = Calories)) + geom_point() + theme_bw()
grid.arrange(g1,g2,g3,g4, nrow = 2)
```

The relationship between these variables depends on the heart rate and on the body weight, that is why the graphs are so unclear. Nevertheless, the graph between METs and calories (bottom left) suggests that there is linear relationship between them that depends only on each user.

### Loading sleep data
Sleep data by day. Will be interesting to ask if the users who input sleep data also logged more days or use their device more for longer during waking hours?

To check the credibility of the data, we plot the difference between the sleep minutes and wake minutes. We call this tiredness but it could be due to insomnia or some other factor like misclassification by the device. No value should be negative, unless they are sleeping on their feet.

```{r load sleep data, message=FALSE, warning=FALSE}
sleepDay <- read_csv(paste0(data_path,"sleepDay_merged.csv"), 
    col_types = cols(Id = col_character(), 
        SleepDay = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

mutate(sleepDay, tiredness = TotalTimeInBed - TotalMinutesAsleep) %>% group_by(Id) %>% summarise(tired = mean(tiredness)) %>% ggplot() + geom_col(aes(x=Id, y= tired)) + theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs(ylab = "Minutes", title = "Tiredness", subtitle = "Mean minutes awake in bed by user")
```

Most users mean difference is half an hour, or less, meaning they do not take long to fall sleep and get out of bed easily. Users 1844 and 3977 spend almost 3 hours in bed without sleeping. This could mean their data is not credible or is part of their routine. Checking user 1844 it seems that there are only 3 sleep records and all three have the exact same number of total minutes in bed: 961. This probably means the data for this user is unreliable. User 3977 seems to have a genuine sleep problem, since there is no day that they do not spend more than 100 minutes awake in bed. Using the lubridate package function wday() I saw that this happens any day of the week (I thought they could be only tracking their sleep on weekends). I will not show data for these users, but will filter it out.

```{r sleep, message=FALSE, warning=FALSE}
sleepDay <- sleepDay %>% filter(Id != 3977333714, Id != 1844505072)

sleepDay %>% ggplot(aes(x = Id, y = TotalMinutesAsleep)) + geom_boxplot() + geom_jitter() + theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs(ylab = "Minutes", title = "Total Minutes Asleep", subtitle = "Boxplot of total daily minutes asleep by user")
```


From the above graph, it is clear that the data for 2026 and 7007 is also unreliable due to very few data points and less than 100 minutes of sleep. It is not clear that we should filter all the records that are lower than 200 without further data exploration. People are able to sleep for less than 3 hours for a few days. We will filter records from users with fewer than 3 days of sleep tracking, though:

```{r filter sleep low, message=FALSE, warning=FALSE}
sleepDay <- sleepDay %>% group_by(Id) %>% filter(n()>3)
```

### Load weight info

```{r weight info, message=FALSE, warning=FALSE}
weightLogInfo <- read_csv(paste0(data_path,"weightLogInfo_merged.csv"),
    col_types = cols(Id = col_character(), 
        Date = col_datetime(format = "%m/%d/%Y %H:%M:%S %p")))

skim_without_charts(weightLogInfo)
```
We load the final file. Only 8 users out of the 33 input their weight at all. Of them, only two do so consistently. It could be interesting to see if these two represent a distinct segment of users that tracks with their device more often and are more seriously into fitness? Curiously, whether the weight is automatically input does not make a difference on the number of records, suggesting that this is not such an important feature:

```{r weight summary by user}
weightLogInfo %>% group_by(Id, IsManualReport) %>% summarise(count = n(), mean = mean(WeightKg), sd = sd(WeightPounds)) %>% arrange(desc(count))
```

Great! We now have a very good idea of how the data is organized and which kind of questions we can answer with it.
